\documentclass[11pt,a4paperpaper,]{article}

\input{precis_header}

\title{Pr\'ecis of \emph{Cognition as a sequential decision problem}}
\author{Frederick Callaway}

\begin{document}

\maketitle

\begin{quote}
\emph{We must be prepared to accept the possibility that what we call
``the environment'' may lie, in part, within the skin of the biological
organism.} ---Herb Simon \citeyearpar{simon1955behavioral}
\end{quote}

How can we build theoretically satisfying and practically useful models of the human mind? Historically, there have been two broad approaches. The \emph{rational} approach, exemplified by the work of David Marr \citeyearpar{marr1982vision} and John Anderson \citeyearpar{anderson1990adaptive}, focuses on characterizing the problems people have to solve and the optimal solutions to those problems. Under the assumption that the mind is well adapted to its environment, these optimal solutions then serve as models of cognition. Rational models are satisfying because they tell us \emph{why} the mind works the way it does, and they are useful because they allow us to make generalizable predictions about how people will behave in new environments (i.e., rationally). However, by construction, such models don't explain \emph{how} the mind achieves the rational ideal, and a growing list of systematic cognitive biases \citep{kahneman2011thinking} draws their predictive utility into question.

In contrast, the \emph{mechanistic} approach focuses on identifying the cognitive processes underlying behavior, often with an emphasis on explaining the behavioral idiosyncrasies that rational models gloss over. This approach can potentially tell us how the mind actually works, and it can produce extremely accurate models. However, lacking the optimality constraint, there is an enormous space of possible mechanistic models, and they often have many free parameters that are tuned for specific experimental setups. We are thus left wondering why this specific model fit the data best, and whether it would continue to make good predictions in a slightly different context.

Although the rational and mechanistic approaches have traditionally been viewed as conflicting, the past decade has seen a resurgence of an old idea \citep{simon1955behavioral}: rationality can be seen as a property of cognitive mechanisms themselves. Specifically, a cognitive mechanism is rational if it makes optimal use of limited cognitive resources. Going under various names---cognitively bounded rational analysis \citep{howes2009rational}, computational rationality \citep{lewis2014computational,gershman2015computational}, and resource-rational analysis \citep{griffiths2015rational,lieder2020resourcerational} to name a few---this view suggests that we should not expect people to be rational in the traditional sense of taking actions that maximize expected utility \citep{vonneumann1944theory}. Instead, we should expect people to select actions using mental strategies that strike a good tradeoff between the utility of the chosen action and the cognitive cost of making the decision.

But what defines a ``good'' tradeoff between action utility and cognitive cost? And how can we identify mental strategies that achieve such a tradeoff? In my dissertation, I suggest answers to these questions based on a key insight: \emph{a rational mental strategy is one that optimally solves the sequential decision problem posed by one's internal computational environment}. Under this view, cognition is a problem of stringing together a series of basic cognitive operations, or ``computations'', in the service of choosing what to do in the world. An optimal cognitive process strings those basic operations together in such a way that maximizes the difference between the utility of the ultimate behavior and the total cost of all the cognitive operations that support the behavior.

The dissertation consists of six chapters. In the first chapter, I introduce the idea that cognition is a sequential decision problem, and provide theoretical context motivating my formalization of this idea. In the second chapter, I give a complete specification of that formalization using the framework of \emph{metalevel Markov decision processes}. In the next three chapters, I illustrate how my colleagues and I have applied the framework to understand how people think about the present (attention), the past (memory), and the future (planning). In each case, we use process-tracing data to reveal in which ways people's cognitive processes are consistent with and different from optimal cognitive processes. Taken together, the results suggest that people's mental strategies are well-adapted to the limitations posed by their cognitive architectures, often in ways that could not be revealed without considering the sequential nature of cognition. In the final chapter, I identify ways in which the framework could be further developed and offer my thoughts on the role of frameworks in cognitive science.


\subsection{Chapters 1 and 2: metalevel Markov decision processes}\label{formal-framework-metalevel-mdps}


\begin{figure}[tbp]
  \centering
  \includegraphics[width=\textwidth]{diagrams/precis/intro.pdf}
  \caption{Sequential decision problems posed by external and internal environments.}
  \label{fig:sequential-intuition}
\end{figure}

What does it mean to say that cognition is a sequential decision problem? One way to understand this claim is as an analogy between the type of problems posed by our external, physical environments and the type of problems posed by our internal, mental environments. To make things concrete, consider the problem facing a delivery robot, illustrated in \figref{fig:sequential-intuition}{a}. Completing the delivery will require visiting a sequence of locations before arriving at the final destination. And at each location, the robot will need to decide where to go next. Thus, the robot faces a sequential decision problem. \figref{fig:sequential-intuition}{b} illustrates how this type of problem is often modeled in artificial intelligence research: a \emph{Markov decision process}, or MDP. At each time step, an agent (here, the robot) takes an \emph{action} (e.g., driving forward). This action causes the environment to enter a new \emph{state} (e.g., one where the robot is in a new location). Additionally, the agent receives a \emph{reward}, a number that captures how good or bad the immediate consequences of the action are. For example, the delivery robot might receive a large positive reward for reaching the destination and a small negative reward every time it moves (capturing the desire to conserve battery life). The robot's goal is to maximize the total reward received.
% After receiving the reward and new state, the agent selects another action and the cycle continues.

\figref{fig:sequential-intuition}{c} illustrates a seemingly very different type of situation: a person trying to come up with a solution to a difficult problem. However, as the diagram suggests, the two cases actually share the same basic structure. Both involve an extended interaction between an agent and an environment; but whereas the robot is interacting with an \emph{external} environment, the thinker is interacting with an \emph{internal} environment: their own mind. Just as the robot makes several moves, and visits several locations before reaching the destination, the thinker has several thoughts, and enters several mental states before discovering the solution. Indeed, as illustrated in \figref{fig:sequential-intuition}{d}, this problem can be modeled in precisely the same way as the delivery problem. However, now the actions correspond to \emph{computations} and the states correspond to \emph{mental states}. Thinking changes one's mental state just as moving changes one's physical state; and it also incurs a cost---at the very least, thinking takes time. Because this MDP describes the metacognitive problem of how to interact with one's own mind, it is called a \emph{metalevel} MDP.

The power of identifying this parallel between external and internal environments is that it allows us to leverage existing knowledge about how to solve MDPs (a substantial chunk of AI research) to build rational mechanistic models of cognition. Indeed, this parallel was identified many years ago by researchers in \emph{rational metareasoning}, a subfield of artificial intelligence that aims to construct artificial agents that make effective use of their limited computational resources \citep{russell1991principles,hay2016principles}. My dissertation simply applies the theoretical tools developed there (in particular metalevel MDPS) to a different problem: reverse-engineering an existing intelligent system that makes effective use of its limited resources---the human mind.

\subsection{Attention}

\begin{figure}[th]
  \centering
  \includegraphics[width=\textwidth]{diagrams/precis/attention.pdf}
  \caption{\captiontitle{Attention}
    \subcap{A} Meta-level MDP. The mental state encodes a distribution over the value of each option in the choice set. A computation corresponds to sampling the value of an option and updating its estimated value by Bayesian inference.
    \subcap{B} Illustration of optimal policy. The optimal policy is less likely to sample from options whose estimated value is highly certain (x axis) or very far from the competitors (far from zero on the y axis). In the three-item case, it is additionally sensitive to the sign of relative value, preferentially attending to high value options.
    \subcap{C} Both people (black) and the model (purple) are equally likely to attend to the better or worse option in binary choice (left). In trinary choice however (right), they are less likely to attend to the worst option in the set as the decision progresses.
    \subcap{D} Both people and the model show increasing fixation durations over the course of a decision.
  }
  \label{fig:attention}
\end{figure}


Consider the problems faced by a diner at a buffet table or a shopper at a supermarket shelf. They are presented with a number of options and must evaluate them until they identify the most desirable one. Previous work suggests that these decisions are made by integrating noisy evidence about the value of each alternative, which is sampled over time. Moreover, this process is guided by visual attention, such that the evidence is strongest for the item currently being looked at; as a result, what we look at has consequences for what we choose \citep{krajbich2010visual}. This raise an important question: \textbf{How do we decide what to pay attention to when making
decisions?}

This problem is naturally cast as a metalevel MDP (\figref{fig:attention}{a}). The (mental) states correspond to the agent's current estimates of (and uncertainty about) the value of each item. The computations correspond to fixating on a given option, drawing a noisy sample of its value, and integrating that information into the corresponding value estimate by Bayesian inference. This sampling and updating process is encoded by the transition function. Finally, the reward function imposes a fixed cost for each sample, an additional switching cost for saccades, and a reward equal to the true value of the chosen option.

Solving the metalevel MDP yields an optimal policy for allocating attention when making decisions. 


% As illustrated in \figref{fig:attention}{b}, the optimal policy is highly sensitive to two key features of the mental state: 1) uncertainty about the true values and (2) differences in the value estimates. In both binary and trinary choice, the policy prefers to sample from items with high uncertainty and whose estimated value is similar to the other items in the choice set. In the case of trinary---but not binary---choice, we additionally see a stark asymmetry in the effect of relative estimated value. While the policy is likely to sample from an item whose value is substantially higher than the competitors, it is unlikely to sample from an item with value well below. In particular, the policy has a strong preference to sample from the items with best or second-best value estimates. Intuitively, this is because sampling those items is most likely to change the choice one makes, by switching the order of the top two contenders.

Do people use a similar strategy to allocate attention when making choices? To address this question, we use two datasets collected by Krajbich, Armel, and Rangel, in which participants chose between junk food snacks (either two or three per trial) while their gaze was recorded with an eye tracker \citep{krajbich2010visual,krajbich2011multialternative}. We can simulate this kind of data from the model by assuming that the attended (sampled) item is fixated and that each sample takes 100ms. Then we can compare the simulated data to the actual recordings.

In the dissertation, I conduct a thorough comparison of optimal and human attention allocation in simple choice. Here, I highlight two of the most striking findings. \figref{fig:attention}{c} shows the probability of fixating on the worst option in the set over the course of a decision. Consistent with \figref{fig:attention}{b}, the model (purple) is equally likely to fixate on the better and worse item throughout the trial; but it becomes less likely to fixate the worse option after some information has accumulated, allowing it to preferentially attend to the top two options. People show the exact same pattern. In the dissertation, I show that find similar patterns in the overall proportion of fixation and the duration of the first fixation. And in the trinary case, we also see an effect of value on the probability of refixating items, further confirming value-directed attention in this case.

Of course, one does not need an optimal model to hypothesize that people tend to look at things they like---indeed, this has been suggested many times before (e.g., \citealp{shimojo2003gaze,gluth2020valuebased,anderson2016attention}). To highlight a more novel (and perhaps, less obvious) prediction, \figref{fig:attention}{d} shows the duration of fixations over the course of a decision. Although the model tends to underpredict the duration of the first two fixations in the three-item case, it captures well three key patterns: (a) the final fixation is shorter, (b) later (but non-final) fixations are longer and (c) fixations are substantially longer in the two-item case. The first occurs because final fixations are cut off when a choice is made, as in previous evidence accumulation models \citep{krajbich2010visual}. The latter two patterns are unique predictions of the optimal model. They arise because more evidence is needed to alter beliefs when their precision is already high; this occurs late in the trial, especially in the two-item case where samples are split between fewer items.

Critically, these qualitative differences in the model predictions in binary and trinary choice are not the result of model fitting. The same set of parameters are used to generate predictions for binary and trinary choice, and the key qualitative differences are highly robust to the values of those parameters. This illustrates the power of rational models to generalize.

This work was published in \emph{PLoS Computational Biology} \citep{callaway2021fixation}.

\subsection{Memory}

\begin{figure}[ph]
  \centering
  \includegraphics[width=\textwidth]{diagrams/precis/memory.pdf}
  \caption{\captiontitle{Memory}
    \subcap{A} Meta-level MDP. The mental state encodes the current recall progress and an estimate of the rate of progress. A computation corresponds to searching for the target memory, generating recall progress.
    \subcap{B} Reaction time as a function of metamemory judgment (feeling of knowing for skip trials, confidence for recall trials), separately for trials in which participants correctly recalled the target vs. skipped without responding.% The models' metamemory judgments are made based on the inferred memory strength at the end of the trial.
    \subcap{C} Multiple-cued recall task. Participants were presented with two images on each trial and could recall the word associated with either of them. Only one cue was visible at a time; participants could flip between them with the D and F keys. At any point they could press J or K to select an image for recall.
    \subcap{D} Timecourse of attention to the first cue, split by its memory strength (operationalized by accuracy in the pretest phase).
  }
  \label{fig:memory}
\end{figure}


Consider next the all-too-familiar situation of running into someone whose name you cannot recall. If it feels as though the name is about to come to you, you may pause before saying hello. But every moment you delay only exacerbates the awkwardness of the situation. \textbf{How do people know when to give up on searching for a memory?}

Most empirical work on metacognition in the domain of memory (or ``metamemory'') has focused on how people are able to monitor their memory states \citep{reder1992determines,eakin2005illusions} and on evaluating the accuracy of those judgments \citep{hart1965memory,vesonder1985ability,dunlosky2007metacomprehension}. Less emphasis, however, has been placed on understanding the function of metamemory judgments \citep{schwartz2017metamemory}. In a highly influential paper, \citet{nelson1990metamemory} proposed that the function of metacognitive systems is to allow effective control of ongoing cognition. For example, they outlined a theory in which a dynamically updated feeling of knowing is used to inform the decision of when to terminate an unsuccessful recall attempt. However, despite this early progress, previous work has not proposed a computational model of how these feeling of knowing estimates might be dynamically generated, nor of how they could be used to control recall efforts. 

In this chapter, I provide such a model, formalizing the decision of when to terminate a memory search as a metalevel MDP (\figref{memory}{a}). Here, the mental states capture the amount of progress one has made towards recalling a memory as well as a metacognitive estimate of the rate of progress (that is, a ``feeling of knowing'' \citealp{hart1965memory}). The computations correspond to continuing to search for the target. The transition function describes how recall progress noisly accumulates through search. Finally, the reward function encodes the value of recalling the item (when a threshold level of progress is reached) and a fixed cost for each moment spent searching.

Solving this metalevel MDP reveals that, perhaps unsurprisingly, it is optimal to give up more quickly on a weak memory for which recall progresses slowly. The model thus captures the consistent empirical finding that people search longer before giving up on memories that they report having a higher feeling of knowing for \citealp{nelson1984comparison,nhouyvanisvong1998rapid,gruneberg1977methodological,lachman1979metamemory}. In one especially striking demonstration of this phenomenon, \citet{costermans1992confidence} found that judgments of memory strength showed opposite relationships with response time when the item was recalled vs. not recalled, with high confidence judgments for items that were recalled quickly, but low feeling-of-knowing judgments for items that were skipped quickly. As shown in \figref{memory}{b}, the optimal model produces this exact pattern, while a model without meta-level control (but the same underlying memory recall process) fails to capture this phenomemon.

One weakness with the above finding, and indeed with many empirical results in metamemory, is that we observe at most one single metacognitive decision in each trial, the decision to terminate search. To provide a stronger test of the sequential search-evaluate loop, my colleagues and I designed a modified cued-recall paradigm in which two candidate memories could be recalled on each trial (\figref{memory}{c}). By tracking attention to the corresponding cues using a keypress-contingent display, we could observe this metacognitive process unfolding even before a memory was recalled or given up on. Interestingly, \figref{memory}{d} shows that, contrary to the decision-making case studied in the previous chapter, the optimal policy preferentially attends to cues associated with stronger memories even when there are only two options. Participants showed the same pattern.

% This chapter is based on a preprint that is currently under review at \emph{Psychological Review}.

\subsection{Planning}

\begin{figure}[ph]
  \centering
  \includegraphics[width=\textwidth]{diagrams/precis/planning.pdf}
  \caption{\captiontitle{Planning}
    \subcap{A} Meta-level MDP. The mental state is a decision-tree, which represents possible future actions (edges), states (nodes), and rewards (green/red). A computation corresponds to considering a future state and expanding the decision tree.
    \subcap{B} Mouselab MDP task. The internal process of expanding a decision tree is externalized by forcing participants to click to reveal the reward to be gained at each state.
    \subcap{C} Adaptation of planning strategy in environments with different reward structures (see main text). Each panel shows the probability of making a second click on the same path as the first click, depending on the value revealed by that first click. Models that capture the qualitative trend are highlighted. % Modulating the distribution of rewards in the environment changes the optimal planning stategy: breadth-first when large rewards are near the initial state, best-first when they are distributed evenly, and depth-first when they are far from the initial state.
  }
  \label{fig:planning}
\end{figure}


Finally, consider the problem faced by a traveler in an unfamiliar country, deciding which cities to visit. Geographical concerns limit which cities theycan travel between, so their first stop will shape the whole trip. But there are far too many possible routes to consider every one. \textbf{How do we know which hypothetical courses of action to evaluate, and which to ignore?}

How people solve problems that require thinking multiple steps ahead has been a focal question since the very earliest attempts to understand the human mind in computational terms \citep{newell1956logic,newell1972human}. Both then and now, most work on human planning has focused on identifying the heuristics people use to select which possibile actions to consider. For example, people might limit the depth of their search \citep{macgregor2001information,keramati2016adaptive,krusche2018adaptive,snider2015prospective}, ``prune'' away initially unpromising courses of action \citep{huys2012bonsai,huys2015interplay}, or avoid planning altogether by relying on habit or ``memoization'' \citep{huys2015interplay,kool2017costbenefit}. However, the questions of why people use those particular heuristics and of predicting which of the many possible heuristics people will employ in any particular case, have been relatively unexplored.

To provide a normative theory of human planning strategies and how they adapt to the structure of the environment, we can model planning---specifically, decision tree search---as a metalevel MDP (\figref{planning}{a}. A mental state corresponds to a partially constructed decision tree, which represents possible sequences of actions and outcomes as a tree-structured graph. A computation corresponds to \emph{node expansion}. This operation determines the cost or reward for visiting a state, integrates that value into the total value of the path leading to that state, and adds the immediate successors of the target state to the search frontier, that is, the set of nodes that can be expanded on the next iteration. The transition function encodes these dynamics---critically, it also encodes prior information the agent may have about where large rewards are likely to be found. Finally, the metalevel reward function assigns a fixed cost for each node expansion operation; when the agent terminates planning, they receive a reward equal to the expected value of the external rewards that will be gained by executing a plan chosen with the current decision tree.

A fundamental challenge for studying human planning is that planning takes place inside a person's head, and thus cannot be directly observed. Early work on human planning addressed this challenge using ``think aloud'' protocols in which participants narrate their planning process \citep{degroot1965thought,newell1972human,chase1973perception}. However, verbal reports are only indirectly related to the cognitive operations involved in planning and do not lend themselves well to precise quantitative modeling. More recently, researchers have tried to infer people's planning algorithms based only on their external actions \citep{huys2015interplay,daw2005uncertaintybased,solway2015evidence,vanopheusden2017computational}. However, the precise nature of a person's planning algorithm is generally only weakly constrained by their actions alone because there are usually many sequences of planning operations that are consistent with each possible choice.

In order to produce the fine-grained process-tracing data necessary to directly test the predictions of an optimal planning model, my colleagues and I designed a new experimental paradigm. Inspired by the Mouselab paradigm, which has been used to study multi-attribute (one-shot) decisions \citep{payne1988adaptive}, our task externalizes planning operations as information-revealing mouse clicks. In our generalization of the paradigm, \emph{Mouselab-MDP}, participants must click future states to see what reward they would gain if they visited that state (\figref{planning}{b}). The sequence of clicks thus reveals the order in which the participant considered each state. In this way, we can evaluate candidate models at the level of individual node expansion operations, providing a stronger and more objective test than is possible with action-based model comparison or verbal reports.

In an unstructured environment (Experiment 1), the optimal planning strategy closely resembles best-first search with a stopping rule that is sensitive to both absolute and relative value; that is, it generally expands nodes on the path that has maximal expected value under the current decision tree and it commits to a plan when it finds one whose expected value is high and/or better than competing plans. A heuristic model designed to capture this strategy explains participants' clicks better than any combination of a number of previously proposed heuristic planning mechanisms such as pruning and satisficing. However, the optimal model still predicts behavior best, achieving the highest out-of-sample likelihood.

When rewards are not uniformly distributed across the states, the optimal planning algorithm can take a very different form. In Experiment 2, we constructed three environments with different reward distributions. In the ``constant variance'' environment all states had the same reward distribution, as in Experiment~1. In the other two environments, most states had small rewards; extreme rewards could only be found in one state on each path: the first state in the ``decreasing variance'' environment and the last state in the ``increasing variance'' environment. We designed these environments such that the optimal planning algorithm resembled a different classical algorithm in each case: breadth-first for decreasing variance, best-first for constant variance, and depth-first for increasing variance. 

\figref{fig:planning-exp2}{c} shows a simple behavioral marker of this adaptation. Considering only trials on which at least two clicks were made, we ask how often people use their second click to continue down the path that they began with their first, depending on the value revealed by that first click. An overall tendency to continue down the same path is consistent with a depth-first strategy, the reverse tendency is consistent with a breadth-first strategy, and high sensitivity to the revealed value is consistent with a best-first strategy. We see that both people and the optimal model adjust their strategy in the different environments, as predicted. Although one heuristic model in each condition resembles the pattern shown by humans and the optimal model, no single heuristic model could capture behavior in all conditions. 

So far, I have focused on the cases where people resemble the optimal model. However, we also found systematic deviations from optimal planning. Most notably, when we removed the search-frontier constraint (third panel of \figref{planning}{b}) in Experiments 3 and 4, we found a strong bias towards considering states in the order in which they would be traversed. This suggests that our metalevel MDP does not capture all the factors constraining human planning in naturalistic settings. In particular, in many cases people may not be able to sample arbitrary future states, and when they can they may have access to a generative model that makes it easier to simulate in temporal order than to reason backwards from effect to cause. If people's planning algorithms are adapted to the naturalistic case, we would expect to see discrepancies when these important constraints are removed. This highlights a key strength of rational models: the cases where the model is ``wrong'' can be just as---if not more---informative than the cases where it's right.

This work was published in \emph{Nature Human Behavior} \citealp{callaway2022rational}.


\subsection{Conclusion}

% Across all three domains, my dissertation research shows how Simon's 1955 insight---that cognitive processes are shaped by the environments both within and outside the mind---can be formalized to generate rational mechanistic models that explain both how and why cognitive processes are the way they are.

My dissertation presents a general framework for modeling cognition as a sequential decision problem: metalevel Markov decision processes. It shows how the framework can be applied to derive rational mechanistic models in three different domains: attention, memory, and planning. And in each case, we find that human behavior showed substantial qualitative alignment with the optimal metalevel policy. Taken together, the results suggest that human cognitive processes are well-adapted to the internal environments in which they operate. More importantly, by formally characterizing the problems posed by those mental environments, and their optimal solutions, we develop a richer understanding of human cognition in each of these domains.

In the final chapter, I identify four key directions in which the metalevel MDP framework could be extended in future work. First, and perhaps most importantly, is the question of how people arrive at highly adaptive mental strategies. Given that explicit ``model-based'' reasoning will fall into a problem of infinite regress (how do you efficiently compute what to compute next?), I suggest (echoing \citealp{lieder2017strategy}) that people learn metalevel policies by model-free reinforcement learning (RL). However, it remains unclear how people are able to learn mental strategies so rapidly (as evidenced by the under-performance of RL methods in the Mouselab MDP task; \citealp{jain2019how}). The next three directions all concern architectural assumptions of metalevel MDPs as proposed: (1) that the agent has complete access to their own mental state, (2) that the world does not change while the agent is computing, and (3) that the metalevel MDP (i.e., the cognitive architecture) is fixed and not subject to adaptation or selection pressure. I hope to explore the consequences of relaxing these assumptions in my own future work.

In the final paragraphs, I reflect on the role of frameworks in cognitive science. Having spent most of my graduate career developing and applying one such framework (metalevel MDPs), I found that the theoretical commitments and technical requirements often constrained my research just as much as empowered it. However, upon further reflection, I suggest that these constraints are actually the main benefit of using a framework; they filter the incomprehensibly large space of possible cognitive theories into a more managable set. However, limiting our thinking in this way also has costs; in particular, no one framework is likely to provide useful constraints for understanding every aspect of cognition. For this reason, I urge skepticism and humility when working with frameworks. We should view frameworks not as goals in and of themselves, as possible candidates for a grand unifying theory of cognition, but rather as means to an end, as instruments to be applied in the ongoing project of understanding the human mind. I hope that this dissertation has provided one such instrument to the cognitive science community.



% I discuss 
% drugowitsch2012cost,tajima2016optimal,jang2021optimal

\pagebreak

\renewenvironment{APACrefURL}[1][]{}{}
\renewcommand{\url}[1]{}
\renewenvironment{APACrefDOI}[1][]{}{}
\renewcommand{\doi}[1]{}

\bibliography{references,extra}


\end{document}